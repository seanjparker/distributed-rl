{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.optim import Adam\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "from scipy import signal\n",
    "\n",
    "import os, subprocess, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    # Only works on Mac/Linux\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, obs_dimensions, act_dimensions):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(obs_dimensions, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, act_dimensions),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def get_distribution(self, obs):\n",
    "        return Categorical(logits=self.actor(obs))\n",
    "    \n",
    "    def forward(self, obs, act=None):\n",
    "        # Produce action distributions for given observations, and \n",
    "        # optionally compute the log likelihood of given actions under\n",
    "        # those distributions\n",
    "        pi = self.get_distribution(obs)\n",
    "        logp_a = None\n",
    "        if act is not None:\n",
    "            logp_a = pi.log_prob(act)\n",
    "        return pi, logp_a\n",
    "        \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, obs_dimensions):\n",
    "        super().__init__()\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(obs_dimensions, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, obs):\n",
    "        return torch.squeeze(self.critic(obs), -1)\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, obs_space, act_space):\n",
    "        super().__init__()\n",
    "        \n",
    "        obs_dimensions = obs_space.shape[0]\n",
    "        \n",
    "        # policy network\n",
    "        self.pi = Actor(obs_dimensions, act_space.n)\n",
    "        \n",
    "        # value network\n",
    "        self.v = Critic(obs_dimensions)\n",
    "        \n",
    "        \n",
    "    def step(self, obs):\n",
    "        with torch.no_grad():\n",
    "            pi = self.pi.get_distribution(obs)\n",
    "            action = pi.sample()\n",
    "            logp_a = pi.log_prob(action)\n",
    "            val = self.v(obs)\n",
    "\n",
    "        return action.numpy(), val.numpy(), logp_a.numpy()\n",
    "    \n",
    "    def get_action(self, obs):\n",
    "        return self.step(obs)[0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter definitions\n",
    "num_workers = 1 # same thing as 'world size'\n",
    "pi_lr = 3e-4\n",
    "v_lr = 1e-3\n",
    "epochs = 50 # 50\n",
    "steps_per_epoch = 4000 // num_workers\n",
    "max_ep_len = 1000\n",
    "train_pi_iters = 80\n",
    "train_v_iters = 80\n",
    "gamma = 0.99\n",
    "lam = 0.97\n",
    "clip_ratio_offset = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_cumsum(x, discount):\n",
    "    return signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppo(rank):\n",
    "    print(f'Running basic DDP example on rank {rank}')\n",
    "    setup(rank, num_workers)\n",
    "    \n",
    "    env = gym.make('LunarLander-v2')\n",
    "    obs_space = env.observation_space\n",
    "    act_space = env.action_space\n",
    "\n",
    "    actor_critic = ActorCritic(obs_space, act_space).to('cpu')\n",
    "    ac_ddp = DDP(actor_critic)\n",
    "    \n",
    "    obs_buf  = np.zeros((steps_per_epoch, obs_space.shape[0]), dtype=np.float32)\n",
    "    act_buf  = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    adv_buf  = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    rew_buf  = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    rew_boot_buf  = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    val_buf  = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    logp_buf = np.zeros(steps_per_epoch, dtype=np.float32)\n",
    "    \n",
    "    pi_optim = Adam(ac_ddp.pi.parameters(), lr=pi_lr)\n",
    "    v_optim = Adam(ac_ddp.v.parameters(), lr=v_lr)\n",
    "    \n",
    "    def ppo_pi_loss(data):\n",
    "        obs, action, advantage, old_logp = data['obs'], data['act'], data['adv'], data['logp']\n",
    "        \n",
    "        pi, logp = ac_ddp.pi(obs, action)\n",
    "        pi_ratio = torch.exp(logp - old_logp)\n",
    "        clipped_adv = torch.clamp(pi_ratio, 1 - clip_ratio_offset, 1 + clip_ratio_offset) * advantage\n",
    "        pi_loss = -(torch.min(pi_ratio * advantage, clipped_adv)).mean()\n",
    "        return pi_loss\n",
    "    \n",
    "    def ppo_v_loss(data):\n",
    "        obs, adj_rewards = data['obs'], data['rew']\n",
    "        return (ac_ddp.v(obs) - adj_rewards).pow(2).mean()\n",
    "    \n",
    "    def ppo_update():\n",
    "        data = {k: torch.as_tensor(v, dtype=torch.float32)\n",
    "                for k, v in dict(obs=obs_buf, act=act_buf, rew=rew_boot_buf, adv=adv_buf, logp=logp_buf).items()}\n",
    "        \n",
    "        for i in range(train_pi_iters):\n",
    "            pi_optim.zero_grad()\n",
    "            pi_loss = ppo_pi_loss(data)\n",
    "            pi_loss.backward()\n",
    "            pi_optim.step()\n",
    "            \n",
    "        for i in range(train_v_iters):\n",
    "            v_optim.zero_grad()\n",
    "            v_loss = ppo_v_loss(data)\n",
    "            v_loss.backward()\n",
    "            v_optim.step()\n",
    "\n",
    "    obs, ep_reward, ep_len = env.reset(), 0, 0\n",
    "    ep_reward_history = np.zeros(epochs, dtype=np.float32)\n",
    "    for ep in range(epochs):\n",
    "        for t in range(steps_per_epoch):\n",
    "            action, val, logp_a = ac_ddp.step(torch.as_tensor(obs, dtype=torch.float32))\n",
    "            \n",
    "            new_obs, reward, done, _ = env.step(action)\n",
    "            ep_reward += reward\n",
    "            ep_len += 1\n",
    "            \n",
    "            # buf.store(obs, action, reward, val, logp_a)\n",
    "            obs_buf[t] = obs\n",
    "            act_buf[t] = action\n",
    "            rew_buf[t] = reward\n",
    "            val_buf[t] = val\n",
    "            logp_buf[t] = logp_a\n",
    "            \n",
    "            obs = new_obs\n",
    "            \n",
    "            timeout = ep_len == max_ep_len\n",
    "            terminal = done or timeout\n",
    "            epoch_ended = t==steps_per_epoch-1\n",
    "\n",
    "            if terminal or epoch_ended:\n",
    "                if timeout or epoch_ended:\n",
    "                    _, bootstrap_v, _ = ac_ddp.step(torch.as_tensor(obs, dtype=torch.float32))\n",
    "                else:\n",
    "                    bootstrap_v = 0\n",
    "\n",
    "                rews_aug = np.append(rew_buf[:], bootstrap_v)\n",
    "                vals_aug = np.append(val_buf[:], bootstrap_v)\n",
    "                \n",
    "                # GAE-Lambda advantage calculation\n",
    "                gae_deltas = rews_aug[:-1] + gamma * vals_aug[1:] - vals_aug[:-1]\n",
    "                adv_buf[:] = discount_cumsum(gae_deltas, gamma * lam)\n",
    "        \n",
    "                # Computes rewards-to-go, to be targets for the value function\n",
    "                rew_boot_buf[:] = discount_cumsum(rews_aug, gamma)[:-1]\n",
    "\n",
    "                ep_reward_history[ep] = max(ep_reward_history[ep], ep_reward)\n",
    "                obs, ep_reward, done = env.reset(), 0, 0\n",
    "        \n",
    "        ppo_update()\n",
    "        print(f'device: {rank}, epoch: {ep + 1}, max reward: {ep_reward_history[ep]:.3f}')\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "process 0 terminated with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7067f8bf19d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mppo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/distributed-rl-Ad5_6RPz/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    197\u001b[0m                ' torch.multiprocessing.start_process(...)' % start_method)\n\u001b[1;32m    198\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mstart_processes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'spawn'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/distributed-rl-Ad5_6RPz/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/distributed-rl-Ad5_6RPz/lib/python3.8/site-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    108\u001b[0m                 )\n\u001b[1;32m    109\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 raise Exception(\n\u001b[0m\u001b[1;32m    111\u001b[0m                     \u001b[0;34m\"process %d terminated with exit code %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0merror_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: process 0 terminated with exit code 1"
     ]
    }
   ],
   "source": [
    "mp.spawn(ppo, nprocs=num_workers, join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Invalid process group specified",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d0c823f9f253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-c84464a4b797>\u001b[0m in \u001b[0;36mcleanup\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/distributed-rl-Ad5_6RPz/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mdestroy_process_group\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_pg_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid process group specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGroupMember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWORLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid process group specified"
     ]
    }
   ],
   "source": [
    "cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
